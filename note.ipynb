{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    # Defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a cashier working for the coffee shop Heaven Coffee. Customers come to you to place orders. \" \\\n",
    "                \"Your job is to take their orders, answer reasonable questions about the shop & menu only, and assist \" \\\n",
    "                \"them with any issues they may have about their orders. You are not responsible for anything else, \" \\\n",
    "                \"so you must refuse to engage in anything unrelated\"\n",
    "\n",
    "def get_menu_items_options(menu_item_id):\n",
    "    return None\n",
    "\n",
    "def get_menu_item_id_from_name(menu_item_name):\n",
    "    return None\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_menu_items\",\n",
    "            \"description\": \"Get all the options available for the menu item. \" \\\n",
    "                            \"Most customers either don't provide a complete order (i.e. not specifying required options like size)\" \\\n",
    "                            \"or are not ware of all the options available for a menu item. It is your job to help them with both cases.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"menu_item_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The menu item id used in the db.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"menu_item_id\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "        {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_menu_item_id_from_name\",\n",
    "            \"description\": \"Get the menu item id given the name string of the menu item.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"menu_item_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The menu item name.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"menu_item_name\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "              {\"role\": \"user\", \"content\": \"hi, i want a venti latte double shot\"}],\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_sXOXQry4TCGjIVrj2n3Kpsbv', function=Function(arguments='{\"menu_item_name\":\"latte\"}', name='get_menu_item_id_from_name'), type='function')]))]\n"
     ]
    }
   ],
   "source": [
    "# print(chat_completion.choices[0].message)\n",
    "print(chat_completion.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_menu_items_options',\n",
       "   'description': \"Get all the options available for the menu item. Most customers either don't provide a complete order (i.e. not specifying required options like size)or are not aware of all the options available for a menu item. It is your job to help them with both cases.\",\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'menu_item_id': {'type': 'integer',\n",
       "      'description': 'The menu item id used in the db.'}},\n",
       "    'required': ['menu_item_id'],\n",
       "    'additionalProperties': False}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'get_menu_item_from_name',\n",
       "   'description': 'Get the menu item given the name string of the menu item.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'menu_item_name': {'type': 'string',\n",
       "      'description': 'The menu item name.'}},\n",
       "    'required': ['menu_item_name'],\n",
       "    'additionalProperties': False}}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from db_functions import get_menu_item_from_name, OPENAI_TOOLS, create_db_client, MenuItem\n",
    "from model_tool_decorator import model_tool_decorator\n",
    "\n",
    "OPENAI_TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MenuItem(id=20, name='Pecan Crunch Oatmilk Latte', description='270 calories', group='LATTE')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_db_client()\n",
    "get_menu_item_from_name(\"pecan latte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'b', 'c', 'd')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = MenuItem(id=1, name='b', description='c', group='d')\n",
    "a.id, a.name, a.description, a.group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 0,\n",
       " 'c': 3,\n",
       " 'd': 0,\n",
       " 'e': 5,\n",
       " 'f': 0,\n",
       " 'g': 7,\n",
       " 'h': 0,\n",
       " 'i': 9,\n",
       " 'j': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5,\"f\":6, \"g\":7, \"h\":8, \"i\":9, \"j\":10}\n",
    "\n",
    "for k,v in d.items():\n",
    "    if v % 2 == 0:\n",
    "        d[k] = 0\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_orders=[ItemOrder(name='Pecan Crunch Oatmilk Latte', options=[OptionOrder(name='Oatmilk', value='Steamed'), OptionOrder(name='Blonde Espresso Roast', value=2), OptionOrder(name='Pecan', value=4)])]\n"
     ]
    }
   ],
   "source": [
    "from db_functions import OPENAI_TOOLS, add_to_order, ItemOrder, get_current_order\n",
    "\n",
    "a = OPENAI_TOOLS\n",
    "\n",
    "item_order_dict = {'name': 'Pecan Crunch Oatmilk Latte', 'options': [{'name': 'Oatmilk', 'value': 'Steamed'}, {'name': 'Blonde Espresso Roast', 'value': 2}, {'name': 'Pecan', 'value': 4}]}\n",
    "add_to_order(ItemOrder(**item_order_dict))\n",
    "print(get_current_order())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBBBBBBB\n",
      "<class 'db_functions.ItemOrder'>\n",
      "CCCCC\n",
      "BBBBBBBBB\n",
      "item_orders=[ItemOrder(name='Pecan Crunch Oatmilk Latte', options=[OptionOrder(name='Oatmilk', value='Steamed'), OptionOrder(name='Blonde Espresso Roast', value=2), OptionOrder(name='Pecan', value=4)])]\n",
      "[OptionOrder(name='Oatmilk', value='Steamed'), OptionOrder(name='Blonde Espresso Roast', value=2), OptionOrder(name='Pecan', value=4)]\n"
     ]
    }
   ],
   "source": [
    "from db_functions import OPENAI_TOOLS, add_to_order, ItemOrder, get_current_order, upsert_to_order\n",
    "\n",
    "a = OPENAI_TOOLS\n",
    "\n",
    "item_order_dict = {'name': 'Pecan Crunch Oatmilk Latte', 'options': [{'name': 'Oatmilk', 'value': 'Steamed'}, {'name': 'Blonde Espresso Roast', 'value': 2}, {'name': 'Pecan', 'value': 4}]}\n",
    "add_to_order(item_order_dict)\n",
    "order = get_current_order()\n",
    "print(order)\n",
    "\n",
    "first_item = order.item_orders[0]\n",
    "print(first_item.options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Oatmilk', 'value': 'Steamed'}, {'name': 'Blonde Espresso Roast', 'value': 2}, {'name': 'Pecan', 'value': 4}]\n",
      "[{'name': 'Oatmilk', 'value': 'Steamed'}, {'name': 'Blonde Espresso Roast', 'value': 69}, {'name': 'Pecan', 'value': 4}]\n"
     ]
    }
   ],
   "source": [
    "first_item_dict = first_item.model_dump()\n",
    "options_dict = first_item_dict['options']\n",
    "print(options_dict)\n",
    "options_dict[1]['value'] = 69\n",
    "print(options_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBBBBBBB\n",
      "<class 'str'>\n",
      "CCCCC\n",
      "typing.List[db_functions.OptionOrder]\n",
      "AAAAA\n",
      "ZZZZZ\n",
      "BBBBBBBBB\n",
      "item_orders=[ItemOrder(name='Pecan Crunch Oatmilk Latte', options=[OptionOrder(name='Oatmilk', value='Steamed'), OptionOrder(name='Blonde Espresso Roast', value=69), OptionOrder(name='Pecan', value=4)])]\n"
     ]
    }
   ],
   "source": [
    "upsert_to_order(first_item.name, options_dict)\n",
    "order = get_current_order()\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifeiyan/.pyenv/versions/3.11.9/envs/cashier/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_provider\" in AssistantTurn has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_tokens': 8192, 'model': 'claude-3-5-sonnet-20240620', 'system': \"Today's temperature is 69C. Help users with weather info\", 'messages': [{'role': 'user', 'content': 'what is todays temperature'}], 'tools': [{'name': 'respond_fn', 'description': 'provide your response by calling this function with the adequate args', 'input_schema': {'properties': {'temp_today_celcius': {'title': 'Temp Today Celcius', 'type': 'integer'}}, 'required': ['temp_today_celcius'], 'title': 'Response', 'type': 'object'}}], 'stream': False, 'tool_choice': {'type': 'tool', 'name': 'respond_fn'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Message(id='msg_0168Nr8182anfJ6owFJBPuVY', content=[ToolUseBlock(id='toolu_0178Wrh1gUgv5sKSThpw6gqZ', input={'temp_today_celcius': 69}, name='respond_fn', type='tool_use')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=Usage(input_tokens=393, output_tokens=38))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import Model\n",
    "from pydantic import BaseModel\n",
    "\n",
    "m = Model()\n",
    "\n",
    "class Response(BaseModel):\n",
    "    temp_today_celcius: int\n",
    "\n",
    "m.chat(model_name='claude-3.5', message_dicts=[{'role': \"user\", \"content\": \"what is todays temperature\"}],system=\"Today's temperature is 69C. Help users with weather info\", response_format=Response).output_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "foo() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfoo\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(kwargs)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mfoo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: foo() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "def foo(**kwargs):\n",
    "    print(kwargs)\n",
    "\n",
    "foo(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deez nuts'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CallableMeta(type):\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        instance = super().__call__(*args, **kwargs)\n",
    "        return instance.something()\n",
    "\n",
    "class MyClass(metaclass=CallableMeta):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def something(self):\n",
    "        return \"deez nuts\"\n",
    "\n",
    "# Now you can call the class directly\n",
    "MyClass(\"hello\", key=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<openai.OpenAI at 0x1141d6590>,\n",
       " <anthropic.Anthropic at 0x11793dd50>,\n",
       " {<ModelProvider.OPENAI: 'OPENAI'>: None,\n",
       "  <ModelProvider.ANTHROPIC: 'ANTHROPIC'>: None})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cashier.model.model_client import ModelClient\n",
    "from cashier.model.model_util import ModelProvider\n",
    "\n",
    "ModelClient.initialize()\n",
    "ModelClient._oai_client, ModelClient._anthropic_client, ModelClient.model_provider_to_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': {'c': 1}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, ConfigDict\n",
    "import json\n",
    "\n",
    "class B(BaseModel):\n",
    "    c: int\n",
    "\n",
    "class A(BaseModel):\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    b: B\n",
    "\n",
    "\n",
    "\n",
    "A(b=B(c=1)).model_dump(exclude_none=True, exclude_unset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A(a=8838, b=B(c=7231))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from polyfactory.factories.pydantic_factory import ModelFactory\n",
    "from polyfactory.factories import pydantic_factory\n",
    "from typing import Optional, Union\n",
    "\n",
    "class B(BaseModel):\n",
    "    c: int\n",
    "\n",
    "class A(BaseModel):\n",
    "    a: Union[int, str]\n",
    "    b: B\n",
    "class AFactory(ModelFactory[A]):\n",
    "    __model__ = A\n",
    "\n",
    "AFactory.build()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A(a=1740, b=B(c=4642))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelFactory.create_factory(A).build()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cashier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
